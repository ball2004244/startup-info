name: Crawl Startup Data

on:
  schedule:
    - cron: "0 */6 * * *"

  push:
    branches:
      - master

permissions: write-all

jobs:
  get-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install ChromeDriver
        uses: nanasess/setup-chromedriver@v2

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Crawl data
        run: |
          echo "Start crawling process"
          echo "! This process might take a while to crawl the data"
          python3 -u multi_scraper.py
          echo "End crawling!"

      - name: Format data
        run: |
          echo "Start formatting crawled data"
          python3 -u csv_formatter.py
          echo "End formatting!"

      # - name: Upload data to GitHub
      #   uses: EndBug/add-and-commit@v9
      #   with:
      #     author_name: Tam Nguyen
      #     author_email: nguyenminhtam7124@gmail.com
      #     message: Update data
      #     new_branch: data
      #     pull: --rebase --autostash

      - name: Push data to GitHub
        run: |
          git config --global user.name "Tam Nguyen"
          git config --global user.email "nguyenminhtam7124@gmail.com"
          git pull origin data --rebase
          git checkout data
          git add .
          git commit -m "Update data"
          git push origin data
