name: Crawl Startup Data

on:
  push:
    branches:
      - master
  schedule:
    - cron: "0 */6 * * *"

permissions: write-all

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install ChromeDriver
        uses: nanasess/setup-chromedriver@v2
    
      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      # - name: Crawl data
      #   run: |
      #     echo "Start crawling process"
      #     echo "! This process might take a while to crawl the data"
      #     python3 -u scraper.py
      #     echo "End crawling!"
      
      - name: Format data
        run: |
          echo "Start formatting crawled data"
          python3 -u csv_formatter.py
          echo "End formatting!"

      - name: Upload new data to GitHub
        run: |
          git config --local user.email "nguyenminhtam7124@gmail.com"
          git config --local user.name "Tam Nguyen"

          # Check if the branch exists on the remote
          if git rev-parse --verify origin/data >/dev/null 2>&1; then
            git fetch origin data:data
            git checkout data
            git pull
          else
            git checkout -b data
          fi

          git add temp final.csv

          if git diff-index --quiet HEAD --; then
            echo "No files to commit"
          else
            git commit -m "Update data"
            git push origin data
          fi
