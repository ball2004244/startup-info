name: Crawl Startup Data

on:
  schedule:
    - cron: "0 */6 * * *"

  push:
    branches:
      - master

permissions: write-all

jobs:
  get-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install ChromeDriver
        uses: nanasess/setup-chromedriver@v2

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Crawl data
        run: |
          echo "Start crawling process"
          echo "! This process might take a while to crawl the data"
          python3 -u multi_scraper.py
          echo "End crawling!"

      - name: Format data
        run: |
          echo "Start formatting crawled data"
          python3 -u csv_formatter.py
          echo "End formatting!"

      - name: Commit and push
        uses: EndBug/add-and-commit@v9
        with:
          author_name: Tam Nguyen
          author_email: nguyenminhtam7124@gmail.com
          message: "Update data"
          add: "final.csv temp check_set.pkl"
          new_branch: data
          push: origin data --set-upstream --force