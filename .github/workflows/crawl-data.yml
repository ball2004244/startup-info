name: Crawl Startup Data

on:
  schedule:
    - cron: "0 */6 * * *"

  push:
    branches:
      - master

permissions: write-all

jobs:
  get-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install ChromeDriver
        uses: nanasess/setup-chromedriver@v2

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Crawl data
        run: |
          echo "Start crawling process"
          echo "! This process might take a while to crawl the data"
          python3 -u multi_scraper.py
          echo "End crawling!"

      - name: Format data
        run: |
          echo "Start formatting crawled data"
          python3 -u csv_formatter.py
          echo "End formatting!"

      - name: Config GitHub
        run: |
          git config --global user.name "Tam Nguyen"
          git config --global user.email "nguyenminhtam7124@gmail.com"

      - name: Preserve cache
        run: |
          mkdir temp_data
          mv check_set.pkl temp_data/
          git add -A
          git commit -m "Preserve cache"
          git push origin data

      - name: Upload data
        run: |
          mv final.csv temp_data/
          git add -A
          git commit -m "Update data"
          git push origin data
          rm -rf temp_data
